{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the notebook of code written by H. Passmore for the assessment and tuning of Machine Learning algorithms for Capstone 1: Amazon Book Reviews & Ratings Predictor. \n",
    "\n",
    "# Machine Learning Algorithms for Capstone 1\n",
    "_Amazon Book Reviews & Ratings Predictor_\n",
    "\n",
    "_Machine Learning Code_\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the code for assessing and tuning machine learning algorithms to predict ratings from reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Build figures inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup Pandas  \n",
    "pd.set_option('display.width', 350)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "# Setup Seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bring the book_revs dataframe into workspace from the inferential statistics code\n",
    "# import pickle\n",
    "# load the pickled  DataFrame of Science Textbook Reviews from hard drive in 'rb' mode\n",
    "import pickle\n",
    "with open('book_revs_forML.pickle','rb') as f:\n",
    "    book_revs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check dataframe of ratings and review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11546 entries, 0 to 11545\n",
      "Data columns (total 9 columns):\n",
      "asin           11546 non-null object\n",
      "overall        11546 non-null int64\n",
      "reviewText     11546 non-null object\n",
      "summary        11546 non-null object\n",
      "five_not5      11546 non-null object\n",
      "rating_cat     11546 non-null int64\n",
      "token_count    11546 non-null int64\n",
      "caps_count     11546 non-null int64\n",
      "pct_caps       11546 non-null float64\n",
      "dtypes: float64(1), int64(4), object(4)\n",
      "memory usage: 811.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# check input data for Machine Learning: reviewText and rating_cat\n",
    "book_revs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a good book for the science nerd and t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you're a biology/genetics enthusiast, this ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating_cat\n",
       "0  This is a good book for the science nerd and t...           0\n",
       "1  If you're a biology/genetics enthusiast, this ...           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only what we need\n",
    "rev_rate = book_revs.drop(['asin', 'overall', 'summary', 'five_not5', 'token_count', 'caps_count', 'pct_caps'], axis=1)\n",
    "rev_rate.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement tools to Reduce Document Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implement WordNetLemmatizer and build CountVectorizer with tokenizer and lemmatizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "user_defined_stop_words = ['book', 'books', 'read', 'reading']\n",
    "\n",
    "i = stopwords.words('english')\n",
    "j = list(string.punctuation) + user_defined_stop_words\n",
    "\n",
    "stopwords = set(i).union(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessor\n",
    "def preprocess(x):\n",
    "    letters_only = re.sub('[^a-zA-Z]', ' ', str(x))                  # keep alpha only\n",
    "    words = letters_only.lower().split()                            # lowercase everything  \n",
    "    useful_words = [w for w in words if w not in set(stopwords)]    # remove stopwords\n",
    "    return (' '.join(useful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating_cat</th>\n",
       "      <th>clean_revs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11541</th>\n",
       "      <td>Definitely a MUST-READ if you are a home cooki...</td>\n",
       "      <td>1</td>\n",
       "      <td>definitely must home cooking enthusiast want g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11542</th>\n",
       "      <td>Pros: Scientifically informative and solid. Kn...</td>\n",
       "      <td>0</td>\n",
       "      <td>pros scientifically informative solid knowing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11543</th>\n",
       "      <td>Real fun to read. For everybody that is inters...</td>\n",
       "      <td>0</td>\n",
       "      <td>real fun everybody intersted cooking certain p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11544</th>\n",
       "      <td>This book will teach you the chemical secrets ...</td>\n",
       "      <td>0</td>\n",
       "      <td>teach chemical secrets techniques usually used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11545</th>\n",
       "      <td>I paid more than $30 to buy such a superficial...</td>\n",
       "      <td>0</td>\n",
       "      <td>paid buy superficial trivial made big mistake ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  rating_cat                                         clean_revs\n",
       "11541  Definitely a MUST-READ if you are a home cooki...           1  definitely must home cooking enthusiast want g...\n",
       "11542  Pros: Scientifically informative and solid. Kn...           0  pros scientifically informative solid knowing ...\n",
       "11543  Real fun to read. For everybody that is inters...           0  real fun everybody intersted cooking certain p...\n",
       "11544  This book will teach you the chemical secrets ...           0  teach chemical secrets techniques usually used...\n",
       "11545  I paid more than $30 to buy such a superficial...           0  paid buy superficial trivial made big mistake ..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply preprocessor to review text\n",
    "rev_rate['clean_revs'] = rev_rate['reviewText'].apply(preprocess)\n",
    "rev_rate.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11546 entries, 0 to 11545\n",
      "Data columns (total 3 columns):\n",
      "reviewText    11546 non-null object\n",
      "rating_cat    11546 non-null int64\n",
      "clean_revs    11546 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 270.7+ KB\n"
     ]
    }
   ],
   "source": [
    "rev_rate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instantiate the stemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define second preprocessor for tokenization and stemming\n",
    "def preprocess2(text):\n",
    "    stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = [stemmer.stem(t) for t in tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating_cat</th>\n",
       "      <th>clean_revs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11541</th>\n",
       "      <td>Definitely a MUST-READ if you are a home cooki...</td>\n",
       "      <td>1</td>\n",
       "      <td>[definit, must, home, cook, enthusiast, want, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11542</th>\n",
       "      <td>Pros: Scientifically informative and solid. Kn...</td>\n",
       "      <td>0</td>\n",
       "      <td>[pros, scientif, inform, solid, know, chemic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11543</th>\n",
       "      <td>Real fun to read. For everybody that is inters...</td>\n",
       "      <td>0</td>\n",
       "      <td>[real, fun, everybodi, interst, cook, certain,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11544</th>\n",
       "      <td>This book will teach you the chemical secrets ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[teach, chemic, secret, techniqu, usual, use, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11545</th>\n",
       "      <td>I paid more than $30 to buy such a superficial...</td>\n",
       "      <td>0</td>\n",
       "      <td>[paid, buy, superfici, trivial, made, big, mis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  rating_cat                                         clean_revs\n",
       "11541  Definitely a MUST-READ if you are a home cooki...           1  [definit, must, home, cook, enthusiast, want, ...\n",
       "11542  Pros: Scientifically informative and solid. Kn...           0  [pros, scientif, inform, solid, know, chemic, ...\n",
       "11543  Real fun to read. For everybody that is inters...           0  [real, fun, everybodi, interst, cook, certain,...\n",
       "11544  This book will teach you the chemical secrets ...           0  [teach, chemic, secret, techniqu, usual, use, ...\n",
       "11545  I paid more than $30 to buy such a superficial...           0  [paid, buy, superfici, trivial, made, big, mis..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_rate['clean_revs'] = rev_rate['clean_revs'].apply(preprocess2)\n",
    "rev_rate.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [good, scienc, nerd, non, scienc, alik, lot, g...\n",
       "1    [your, biologygenet, enthusiast, great, offer,...\n",
       "2    [bought, daughter, borrow, frank, mccourt, wan...\n",
       "3    [recommend, tour, guid, ireland, extrem, funni...\n",
       "4    [school, recent, upgrad, chemistri, honor, lev...\n",
       "5    [confus, explain, poor, overal, graphic, color...\n",
       "6    [lot, cool, experi, complet, fun, process, enjoy]\n",
       "7          [great, condit, better, expect, ship, fast]\n",
       "Name: clean_revs, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_rate.clean_revs[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X & y, split train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11546,)\n",
      "(11546,)\n"
     ]
    }
   ],
   "source": [
    "# store the feature matrix (X) and response vector (y) \n",
    "# uppercase X because it's an m x n matrix\n",
    "X = rev_rate.clean_revs\n",
    "\n",
    "# lowercase y because it's a m x 1 vector\n",
    "y = rev_rate.rating_cat\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Training set sample size: 8659\n",
      "X Testing set sample size: 2887\n",
      "y Training set sample size: 8659\n",
      "y Testing set sample size: 2887\n"
     ]
    }
   ],
   "source": [
    "# split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"X Training set sample size:\", (X_train.shape[0]))\n",
    "print(\"X Testing set sample size:\", (X_test.shape[0]))\n",
    "print(\"y Training set sample size:\", (y_train.shape[0]))\n",
    "print(\"y Testing set sample size:\", (y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.336412980714\n",
      "0.336335296155\n"
     ]
    }
   ],
   "source": [
    "# Double check stratification\n",
    "print(np.mean(y_train == 0))\n",
    "print(np.mean(y_test == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7665    [rainforest, grew, around, susan, k, mitchel, ...\n",
      "1141    [consequ, develop, electron, superintellig, fr...\n",
      "Name: clean_revs, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize, fit, output document-term matrix with two vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# instantiate two vectorizers\n",
    "vect = CountVectorizer(stop_words='english', lowercase=False, analyzer='word', tokenizer=None) \n",
    "tfidf = TfidfVectorizer(stop_words='english', max_df=0.7, lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-57-6b239da345da>\u001b[0m(4)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      3 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 4 \u001b[0;31m\u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m\u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/pgagnon/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m(2865)\u001b[0;36mrun_code\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2864 \u001b[0;31m                \u001b[0;31m# Reset our crash handler in place\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2865 \u001b[0;31m                \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexcepthook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_excepthook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2866 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> a\n",
      "self = <ipykernel.zmqshell.ZMQInteractiveShell object at 0x10664d710>\n",
      "code_obj = <code object <module> at 0x1a0e0f1f60, file \"<ipython-input-57-6b239da345da>\", line 4>\n",
      "result = <ExecutionResult object at 1a13878748, execution_count=57 error_before_exec=None error_in_exec=None result=None>\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/pgagnon/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m(2881)\u001b[0;36mrun_code\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2880 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2881 \u001b[0;31m            \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2882 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/pgagnon/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m(2882)\u001b[0;36mrun_code\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2881 \u001b[0;31m            \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2882 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2883 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "--Return--\n",
      "False\n",
      "> \u001b[0;32m/Users/pgagnon/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m(2882)\u001b[0;36mrun_code\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2881 \u001b[0;31m            \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2882 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0moutflag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2883 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/pgagnon/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m(2799)\u001b[0;36mrun_ast_nodes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2798 \u001b[0;31m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2799 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_run_exec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2800 \u001b[0;31m                \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/pgagnon/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m(2800)\u001b[0;36mrun_ast_nodes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2799 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_run_exec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2800 \u001b[0;31m                \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2801 \u001b[0;31m                \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/pgagnon/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m(2801)\u001b[0;36mrun_ast_nodes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2800 \u001b[0;31m                \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2801 \u001b[0;31m                \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2802 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/pgagnon/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m(2802)\u001b[0;36mrun_ast_nodes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2801 \u001b[0;31m                \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2802 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2803 \u001b[0;31m                    \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-6b239da345da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX_train_dtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \"\"\"\n\u001b[0;32m--> 836\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 266\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mtoken_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/pgagnon/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m(2803)\u001b[0;36mrun_ast_nodes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2802 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2803 \u001b[0;31m                    \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2804 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "--Return--\n",
      "True\n",
      "> \u001b[0;32m/Users/pgagnon/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m(2803)\u001b[0;36mrun_ast_nodes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2802 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2803 \u001b[0;31m                    \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2804 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/Users/pgagnon/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m(2700)\u001b[0;36mrun_cell\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   2699 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 2700 \u001b[0;31m                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_execution_succeeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   2701 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "# Apply CountVectorizer ('vect') to stemmed tokens to learn training data vocabulary\n",
    "# then use it to create a document-term matrix\n",
    "#import ipdb \n",
    "#ipdb.set_trace()\n",
    "vect.fit(X_train.values)\n",
    "X_train_dtm = vect.transform(X_train.values)\n",
    "\n",
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test.values)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-42ac54086ea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Apply TfidfVectorizer to learn training data vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# then use it to create a document-term matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# examine the document-term matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \"\"\"\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 266\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mtoken_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_stop_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# Apply TfidfVectorizer to learn training data vocabulary\n",
    "# then use it to create a document-term matrix\n",
    "X_train_tfidf = tfidf.fit_transform(X_train.values)\n",
    "\n",
    "# examine the document-term matrix\n",
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform testing data with tfidif vectorizer with lemmatizer into document-term matrix\n",
    "X_test_tfidf = tfidf.transform(X_test.values)\n",
    "X_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, build the simple model with Naive Bayes for baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate scikit-learn's MultinomialNB() classifier with default parameters\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model using X_train_dtm from CountVectorizer (vect)\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE TFIDF VECTORIZER\n",
    "# train the model using X_train_tfidf from TfidfVectorizer\n",
    "%time nb.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "\n",
    "# calculate F1 Score: a weighted average of the precision and recall (est value at 1 and worst score at 0)\n",
    "metrics.f1_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE TFIDF VECTORIZER\n",
    "# make class predictions for X_test_dtm\n",
    "y_pred_tfidf = nb.predict(X_test_tfidf)\n",
    "\n",
    "# calculate F1 Score: a weighted average of the precision and recall (est value at 1 and worst score at 0)\n",
    "metrics.f1_score(y_test, y_pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the confusion matrix from Count Vectorizer\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE TFIDF VECTORIZER\n",
    "# print the confusion matrix from Count Vectorizer\n",
    "metrics.confusion_matrix(y_test, y_pred_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusions Matrix breakdown for TFIDF Vectorizer with Naive Bayes:\n",
    "True Positives: 1914 reviews correctly predicted as 'five'\n",
    "True Negatives: 17 reviews correctly predicted as 'not5'\n",
    "False Positives: 954 reviews incorrectly predicted to be 'five' but they are 'not5' (Type I error).\n",
    "False Negatives: 2 reviews incorrectly predicted to be 'not5' but they are 'five' (Type II error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE TFIDF VECTORIZER\n",
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob_tfidf = nb.predict_proba(X_test_tfidf)[:, 1]\n",
    "y_pred_prob_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import roc_curve module\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate AUC for simple model\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE TFIDF VECTORIZER\n",
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_tfidf)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARE TFIDF VECTORIZER\n",
    "# calculate AUC for simple model\n",
    "metrics.roc_auc_score(y_test, y_pred_prob_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GridSearchCV on best vectorizer & classifier to pick parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create a list of performace parameters for performace tuning (ngram range, use idf?, best alpha)\n",
    "parameters = {#'ngram_range': [(1, 1), (1, 2), (1,3)], \n",
    "              #'max_df': (0.5, 0.75, 1.0),\n",
    "              #'vect__max_features': [1, 3, 10],\n",
    "              #'min_df' :(0.00001,0.0001,0.001,0.01,1),\n",
    "              #'fit_prior': (True, False),\n",
    "              #'class_prior': (True, False), \n",
    "              'alpha': (0.001, 0.1, 1, 5, 10)\n",
    "             }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to get a list of the all available pipe-items unique keys for the grid parameters\n",
    "sorted(nb.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the grid search by passing the classifier, parameters \n",
    "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
    "\n",
    "gs_mnb = GridSearchCV(nb, parameters, scoring='roc_auc', n_jobs=-1)\n",
    "gs_mnb = gs_mnb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the best accuracy score\n",
    "print('Best score for text:', gs_mnb.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best parameters\n",
    "print('Best parameters:', gs_mnb.best_params_)\n",
    "# Alpha = 1 is the default and picked as best alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine model inputs for further insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# examine the first 50 tokens\n",
    "print(X_train_tokens[0:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# examine the last 50 tokens\n",
    "print(X_train_tokens[-50:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpretation of simple model:__ The Naive Bayes model with all training tokens performs okay, but it is obvious that some of the terms in the document terms matrix are uninformative (see the list of the first 50 tokens). Many of these will be taken care of when we use GridSearchCV to determine the minimum document frequency for tokens. Further, even the list of the last 50 tokens includes words that would be consolidated to one root work with stemming. In the next steps I will implement NLTK's SnowballStemmer as well as identify the best parameters with GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# counting number of words in each doc gives more weight to long docs over short docs\n",
    "# instantiate TF-IDF, fit & transform training document term matrix\n",
    "# get dimensions of new Document-Term Matrix (it is the same as shape of X_train_dtm. Should it be different?)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # I get an error \"lower not found\" when I used this\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_dtm)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build & evaluate pipeline with stemmed vectorizer, TFIDF transformer, & Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a pipeline with the SnowballStemmer & TF-IDF Transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), \n",
    "                             ('mnb', MultinomialNB(fit_prior=False))])\n",
    "\n",
    "text_mnb_stemmed = text_mnb_stemmed.fit(X_train, y_train)\n",
    "\n",
    "predicted_mnb_stemmed = text_mnb_stemmed.predict(X_test)\n",
    "\n",
    "np.mean(predicted_mnb_stemmed == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate F1 Score: a weighted average of the precision and recall (est value at 1 and worst score at 0)\n",
    "metrics.f1_score(y_test, predicted_mnb_stemmed) # I need estimated targets as returned by a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, predicted_mnb_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusions Matrix breakdown:\n",
    "True Positives: 1851 reviews correctly predicted as 'five'\n",
    "True Negatives: 195 reviews correctly predicted as 'not5'\n",
    "False Positives: 776 reviews incorrectly predicted to be 'five' but they are 'not5' (Type I error).\n",
    "False Negatives: 65 reviews incorrectly predicted to be 'not5' but they are 'five' (Type II error).\n",
    "\n",
    "Progress: My True Positive count increased from the Naive Bayes model, but my True Negatives decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the classification report for stemmed Multinomial Naive Bayes model\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted_mnb_stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate predicted probabilities for X_test with stemmed MNB model\n",
    "y_pred_prob_mnb_stemmed = text_mnb_stemmed.predict_proba(X_test)[:, 1]\n",
    "y_pred_prob_mnb_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_mnb_stemmed)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate AUC for stemmed mnb model\n",
    "metrics.roc_auc_score(y_test, y_pred_prob_mnb_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DID NOT RUN. PRIOR RUN OF NGRAM_RANGE -> (1,1) WHICH PARAMETERS ARE IMPORTANT?\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create a list of performace parameters for performace tuning (ngram range, use idf?, best alpha)\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2), (1,3)]} \n",
    "              #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "              #'vect__max_features': [1, 3, 10],\n",
    "              #'vect__min_df' :(0.00001,0.0001,0.001,0.01,1),\n",
    "              #'tfidf__use_idf': (True, False), \n",
    "              #'mnb__alpha': (0.1, 1, 5, 10)}\n",
    "            \n",
    "# Note: the fitting step takes way too long. 10 minutes for just ngrams. Need to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this to get a list of the all available pipe-items unique keys for the grid parameters\n",
    "#sorted(text_mnb_stemmed.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an instance of the grid search by passing the classifier, parameters \n",
    "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
    "\n",
    "gs_mnb_stem = GridSearchCV(text_mnb_stemmed, parameters, n_jobs=-1)\n",
    "gs_mnb_stem = gs_mnb_stem.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# View the best accuracy score\n",
    "print('Best score for text:', gs_mnb_stem.best_score_) \n",
    "# prior run gave: Best score for text: 0.7037764176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get best parameters\n",
    "print('Best parameters:', gs_mnb_stem.best_params_)\n",
    "# prior run with just ngram_range in grid gave: Best parameters: {'vect__ngram_range': (1, 1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build pipeline to fit Random Forest classifier, get feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# classifier pipeline\n",
    "text_rf_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), \n",
    "                             ('rf', RandomForestClassifier())])\n",
    "\n",
    "text_rf_stemmed = text_rf_stemmed.fit(X_train, y_train)\n",
    "\n",
    "predicted_rf_stemmed = text_rf_stemmed.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, predicted_rf_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate F1 Score: a weighted average of the precision and recall (est value at 1 and worst score at 0)\n",
    "metrics.f1_score(y_test, predicted_rf_stemmed) # I need estimated targets as returned by a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the confusion matrix These changed on a new run. Do I need to set random state?\n",
    "metrics.confusion_matrix(y_test, predicted_rf_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusions Matrix breakdown:\n",
    "True Positives: 1622 reviews correctly predicted as 'five'\n",
    "True Negatives: 390 reviews correctly predicted as 'not5'\n",
    "False Positives: 581 reviews incorrectly predicted to be 'five' but they are 'not5' (Type I error).\n",
    "False Negatives: 294 reviews incorrectly predicted to be 'not5' but they are 'five' (Type II error).\n",
    "\n",
    "Progress: My True Positive count decreased from the stemmed Naive Bayes model, but my True Negatives increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the classification report for stemmed Random Forest model\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted_rf_stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate predicted probabilities for X_test with stemmed MNB model\n",
    "y_pred_prob_rf_stemmed = text_rf_stemmed.predict_proba(X_test)[:, 1]\n",
    "y_pred_prob_rf_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_rf_stemmed)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate AUC for stemmed randomforest model\n",
    "metrics.roc_auc_score(y_test, y_pred_prob_rf_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use to get a list of the all available pipe-items unique keys for the grid parameters\n",
    "#sorted(text_rf_stemmed.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find best parameters with GridSearchCV\n",
    "# create a list of performace parameters for performace tuning (ngram range, use idf?, best alpha)\n",
    "params = {'vect__ngram_range': [(1, 1), (1, 2), (1,3)], \n",
    "              #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "              'vect__max_features': [1, 3, 10],\n",
    "              #'vect__min_df' :(0.00001,0.0001,0.001,0.01,1),\n",
    "              #'rf__min_samples_leaf': (1, 3, 10),\n",
    "              #'rf__min_samples_split': (1, 3, 10),\n",
    "              #'tfidf__use_idf': (True, False), \n",
    "              #'mnb__alpha': (0.1, 1, 5, 10)\n",
    "         }\n",
    "\n",
    "#Note: Took 15 minutes to run just ngrams & max features. best parameters = max feat, 1, ngram (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an instance of the grid search by passing the classifier, parameters \n",
    "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
    "\n",
    "gs_rf_stem = GridSearchCV(text_rf_stemmed, params, n_jobs=-1)\n",
    "gs_rf_stem = gs_rf_stem.fit(X_train, y_train) # this is the slow step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# View the best accuracy score\n",
    "print('Best score for text:', gs_rf_stem.best_score_) \n",
    "# prior run gave: Best score for text: 0.663587019286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get best parameters\n",
    "print('Best parameters:', gs_rf_stem.best_params_)\n",
    "# prior run gave: Best parameters: {'vect__max_features': 1, 'vect__ngram_range': (1, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# looking into classifier\n",
    "print(text_rf_stemmed.steps[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get array of Random Forest feature importances\n",
    "text_rf_stemmed.steps[2][1].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print feature importances from random forest classifier (not from grid search) \n",
    "features = pd.DataFrame(text_rf_stemmed.steps[2][1].feature_importances_,\n",
    "                       columns= ['importance']).sort_values('importance', ascending=False)\n",
    "features.head(10)\n",
    "\n",
    "# I wanted to inlcude 'index = X_train.columns,' to get features names and feature importances\n",
    "# This part does not work. How do I access feature names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to finish getting most important features\n",
    "# run statistical comparisons of results between categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build pipeline to fit Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Logistic Regression Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# classifier pipeline. Previous GridSearch indicated C=0.1 as best parameter for Logistic Regression classifier\n",
    "text_logreg_stemmed = Pipeline([('vect', stemmed_count_vect),('logreg', LogisticRegression(C=0.1))])\n",
    "\n",
    "text_logreg_stemmed = text_logreg_stemmed.fit(X_train, y_train)\n",
    "\n",
    "predicted_logreg_stemmed = text_logreg_stemmed.predict(X_test)\n",
    "\n",
    "metrics.accuracy_score(y_test, predicted_logreg_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate F1 Score: a weighted average of the precision and recall (est value at 1 and worst score at 0)\n",
    "metrics.f1_score(y_test, predicted_logreg_stemmed) # I need estimated targets as returned by a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all logreg parameters are default except tuned C=0.1\n",
    "text_logreg_stemmed.steps[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the confusion matrix These changed on a new run. Do I need to set random state?\n",
    "metrics.confusion_matrix(y_test, predicted_logreg_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the classification report for stemmed Logistic Regression model\n",
    "print(classification_report(y_test, predicted_logreg_stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate predicted probabilities for X_test with stemmed Logistic Regression model\n",
    "y_pred_prob_logreg_stemmed = text_logreg_stemmed.predict_proba(X_test)[:, 1]\n",
    "y_pred_prob_logreg_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate ROC curve values: fpr, tpr, thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_logreg_stemmed)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate AUC for stemmed randomforest model\n",
    "metrics.roc_auc_score(y_test, y_pred_prob_logreg_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use to get a list of the all available pipe-items unique keys for the grid parameters\n",
    "#sorted(text_logreg_stemmed.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find best parameters with GridSearchCV\n",
    "# create a list of performace parameters for performace tuning (ngram range, use idf?, best alpha)\n",
    "params = {'logreg__C' : (0.001, 0.01, 0.1, 1, 5, 10)} # first run indicted 0.1 best value of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an instance of the grid search by passing the classifier, parameters \n",
    "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
    "\n",
    "gs_logreg_stem = GridSearchCV(text_logreg_stemmed, params, n_jobs=-1)\n",
    "gs_logreg_stem = gs_logreg_stem.fit(X_train, y_train) # this is the slow step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# View the best accuracy score\n",
    "print('Best score for text:', gs_logreg_stem.best_score_) \n",
    "# prior results: Best score for text: 0.753204758055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get best parameters\n",
    "print('Best parameters:', gs_logreg_stem.best_params_)\n",
    "# prior results: Best parameters: {'logreg__C': 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try fitting with Support Vector Machines (SVM) algorithm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=5, tol=None,\n",
    "                        random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "metrics.accuracy_score(y_test, predicted_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, predicted_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate F1 Score: a weighted average of the precision and recall (est value at 1 and worst score at 0)\n",
    "metrics.f1_score(y_test, predicted_svm) # I need estimated targets as returned by a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the confusion matrix These changed on a new run. Do I need to set random state?\n",
    "metrics.confusion_matrix(y_test, predicted_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a list of the all available pipe-items unique keys for the grid parameters\n",
    "#sorted(text_clf_svm.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply GridSearchCV\n",
    "\n",
    "# create a list of performace parameters for performace tuning (ngram range, use idf?, best alpha)\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf-svm__alpha': (1e-2, 1e-3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an instance of the grid search by passing the classifier, parameters \n",
    "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
    "\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters, n_jobs=-1) \n",
    "gs_clf_svm = gs_clf_svm.fit(X_train, y_train)\n",
    "# took too long\n",
    "\n",
    "# View the best accuracy score\n",
    "print('Best score for text:', gs_clf_svm.best_score_) \n",
    "\n",
    "# View the best parameters\n",
    "print('Best parameters:', gs_clf_svm.best_params_) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
